/**
 * Enriched lesson content for seeding.
 * Each entry maps a lesson title to rich markdown content
 * that gets converted to ContentBlock JSON by mdToBlocks().
 */
export const ENRICHED_CONTENT: Record<string, string> = {

  // ========== COURSE 0: Desarrollo Web Full Stack ==========

  // --- Module 1: HTML y CSS Fundamentals ---

  'Estructura HTML5': '## Estructura HTML5\n\nHTML5 introdujo etiquetas semánticas que mejoran la accesibilidad y el SEO. Cada página debe tener una estructura clara con header, main y footer.\n\n```html\n<!DOCTYPE html>\n<html lang="es">\n<head>\n  <meta charset="UTF-8">\n  <title>Mi Sitio</title>\n</head>\n<body>\n  <header><nav>Menú</nav></header>\n  <main>\n    <article>\n      <section>Contenido</section>\n    </article>\n  </main>\n  <footer>Pie de página</footer>\n</body>\n</html>\n```\n\n> Tip: Usa siempre etiquetas semánticas en lugar de divs genéricos para mejorar la accesibilidad.',

  'CSS3 y Flexbox': '## CSS3 y Flexbox\n\nFlexbox es un modelo de layout unidimensional que facilita la distribución de elementos en un contenedor. Es ideal para navbars, cards y centrado de contenido.\n\n```css\n.container {\n  display: flex;\n  justify-content: space-between;\n  align-items: center;\n  gap: 1rem;\n}\n\n.item {\n  flex: 1;\n  padding: 1rem;\n  background: #f0f0f0;\n  border-radius: 8px;\n}\n```\n\n> Tip: Usa gap en lugar de margin para espaciar elementos dentro de un contenedor flex.',

  'Responsive Design': '## Responsive Design\n\nEl enfoque mobile-first significa diseñar primero para pantallas pequeñas y luego agregar estilos para pantallas más grandes usando media queries.\n\n```css\n.card {\n  width: 100%;\n  padding: 1rem;\n}\n\n@media (min-width: 768px) {\n  .card {\n    width: 50%;\n  }\n}\n\n@media (min-width: 1024px) {\n  .card {\n    width: 33.33%;\n  }\n}\n```\n\n> Tip: Siempre usa unidades relativas (rem, %, vw) en lugar de píxeles fijos para mayor flexibilidad.',

  // --- Module 2: JavaScript Moderno ---

  'Variables y Tipos de Datos': '## Variables y Tipos de Datos\n\nJavaScript moderno usa let y const en lugar de var. Los tipos primitivos incluyen string, number, boolean, null, undefined y symbol.\n\n```javascript\nconst nombre = "Ana";\nlet edad = 25;\nconst activo = true;\n\nconst usuario = { nombre, edad, activo };\nconst { nombre: n, edad: e } = usuario;\n\nconst colores = ["rojo", "azul"];\nconst [primero, segundo] = colores;\n```\n\n> Tip: Usa const por defecto y let solo cuando necesites reasignar. Nunca uses var en código moderno.',

  'Funciones y Arrow Functions': '## Funciones y Arrow Functions\n\nLas arrow functions ofrecen una sintaxis concisa y no crean su propio contexto this. Son ideales para callbacks y funciones cortas.\n\n```javascript\nconst sumar = (a, b) => a + b;\n\nconst numeros = [1, 2, 3, 4, 5];\nconst pares = numeros.filter(n => n % 2 === 0);\nconst dobles = numeros.map(n => n * 2);\nconst total = numeros.reduce((acc, n) => acc + n, 0);\n\nconsole.log(pares);  // [2, 4]\nconsole.log(dobles); // [2, 4, 6, 8, 10]\n```\n\n> Tip: Usa arrow functions para callbacks pero funciones regulares para métodos de objetos que necesiten this.',

  'Promesas y Async/Await': '## Promesas y Async/Await\n\nAsync/await simplifica el manejo de operaciones asíncronas. Es azúcar sintáctica sobre promesas que hace el código más legible.\n\n```javascript\nasync function obtenerUsuarios() {\n  try {\n    const res = await fetch("https://api.ejemplo.com/usuarios");\n    if (!res.ok) throw new Error("Error en la petición");\n    const datos = await res.json();\n    return datos;\n  } catch (error) {\n    console.error("Fallo:", error.message);\n  }\n}\n\nobtenerUsuarios().then(data => console.log(data));\n```\n\n> Tip: Siempre envuelve tus llamadas async/await en try/catch para manejar errores correctamente.',

  // --- Module 3: React Fundamentos ---

  'Componentes y JSX': '## Componentes y JSX\n\nLos componentes funcionales son la forma moderna de construir interfaces en React. JSX permite escribir HTML dentro de JavaScript.\n\n```jsx\nfunction Saludo({ nombre }) {\n  return (\n    <div className="saludo">\n      <h1>Hola, {nombre}!</h1>\n      <p>Bienvenido a la aplicación.</p>\n    </div>\n  );\n}\n\nexport default function App() {\n  return <Saludo nombre="Carlos" />;\n}\n```\n\n> Tip: Cada componente debe tener una sola responsabilidad. Si crece demasiado, divídelo en componentes más pequeños.',

  'Estado y Props': '## Estado y Props\n\nProps son datos que un componente padre pasa a sus hijos (de solo lectura). El estado es datos internos que el componente puede modificar.\n\n```jsx\nfunction Contador({ inicial = 0 }) {\n  const [cuenta, setCuenta] = useState(inicial);\n\n  return (\n    <div>\n      <p>Cuenta: {cuenta}</p>\n      <button onClick={() => setCuenta(cuenta + 1)}>\n        Incrementar\n      </button>\n    </div>\n  );\n}\n\n// Uso: <Contador inicial={5} />\n```\n\n> Tip: Las props fluyen hacia abajo (padre a hijo). Si necesitas comunicar hacia arriba, pasa funciones como props.',

  'Hooks: useState y useEffect': '## Hooks: useState y useEffect\n\nuseState maneja estado local y useEffect ejecuta efectos secundarios como llamadas a APIs o suscripciones.\n\n```jsx\nfunction Usuarios() {\n  const [usuarios, setUsuarios] = useState([]);\n  const [cargando, setCargando] = useState(true);\n\n  useEffect(() => {\n    fetch("/api/usuarios")\n      .then(res => res.json())\n      .then(data => {\n        setUsuarios(data);\n        setCargando(false);\n      });\n  }, []);\n\n  if (cargando) return <p>Cargando...</p>;\n  return <ul>{usuarios.map(u => <li key={u.id}>{u.nombre}</li>)}</ul>;\n}\n```\n\n> Tip: El array de dependencias vacío [] hace que useEffect se ejecute solo al montar el componente.',

  // --- Module 4: React Avanzado ---

  'Context API y Zustand': '## Context API y Zustand\n\nZustand es una librería ligera de estado global que simplifica el manejo de estado compartido entre componentes sin el boilerplate de Redux.\n\n```typescript\nimport { create } from "zustand";\n\ninterface AuthStore {\n  user: string | null;\n  login: (name: string) => void;\n  logout: () => void;\n}\n\nconst useAuthStore = create<AuthStore>((set) => ({\n  user: null,\n  login: (name) => set({ user: name }),\n  logout: () => set({ user: null }),\n}));\n\n// En componente: const user = useAuthStore(s => s.user);\n```\n\n> Tip: Zustand no necesita Provider. Úsalo para estado global simple y Context API para estado de tema o idioma.',

  'React Router': '## React Router\n\nReact Router v6 permite crear navegación del lado del cliente con rutas declarativas, layouts anidados y carga lazy.\n\n```jsx\nimport { BrowserRouter, Routes, Route } from "react-router-dom";\n\nfunction App() {\n  return (\n    <BrowserRouter>\n      <Routes>\n        <Route path="/" element={<Layout />}>\n          <Route index element={<Home />} />\n          <Route path="cursos" element={<Cursos />} />\n          <Route path="cursos/:id" element={<DetalleCurso />} />\n          <Route path="*" element={<NoEncontrado />} />\n        </Route>\n      </Routes>\n    </BrowserRouter>\n  );\n}\n```\n\n> Tip: Usa Outlet en el Layout para renderizar las rutas hijas y useParams para acceder a parámetros de URL.',

  'Formularios con React Hook Form': '## Formularios con React Hook Form\n\nReact Hook Form junto con Zod ofrece validación de formularios con tipado seguro y excelente rendimiento.\n\n```jsx\nimport { useForm } from "react-hook-form";\nimport { zodResolver } from "@hookform/resolvers/zod";\nimport { z } from "zod";\n\nconst schema = z.object({\n  email: z.string().email("Email inválido"),\n  password: z.string().min(8, "Mínimo 8 caracteres"),\n});\n\nfunction LoginForm() {\n  const { register, handleSubmit, formState: { errors } } = useForm({\n    resolver: zodResolver(schema),\n  });\n  const onSubmit = (data) => console.log(data);\n  return <form onSubmit={handleSubmit(onSubmit)}>...</form>;\n}\n```\n\n> Tip: Zod infiere tipos TypeScript automáticamente con z.infer<typeof schema>.',

  // --- Module 5: Node.js y Express ---

  'Introducción a Node.js': '## Introducción a Node.js\n\nNode.js permite ejecutar JavaScript en el servidor. Usa un modelo de I/O no bloqueante basado en eventos, ideal para aplicaciones en tiempo real.\n\n```javascript\nconst http = require("http");\n\nconst server = http.createServer((req, res) => {\n  res.writeHead(200, { "Content-Type": "application/json" });\n  res.end(JSON.stringify({ mensaje: "Hola desde Node.js" }));\n});\n\nserver.listen(3000, () => {\n  console.log("Servidor corriendo en http://localhost:3000");\n});\n```\n\n> Tip: Node.js es single-threaded. Nunca bloquees el event loop con operaciones síncronas pesadas.',

  'API REST con Express': '## API REST con Express\n\nExpress simplifica la creación de APIs REST con un sistema de rutas y middleware intuitivo.\n\n```javascript\nconst express = require("express");\nconst app = express();\napp.use(express.json());\n\nlet tareas = [];\n\napp.get("/api/tareas", (req, res) => res.json(tareas));\n\napp.post("/api/tareas", (req, res) => {\n  const tarea = { id: Date.now(), ...req.body };\n  tareas.push(tarea);\n  res.status(201).json(tarea);\n});\n\napp.delete("/api/tareas/:id", (req, res) => {\n  tareas = tareas.filter(t => t.id !== +req.params.id);\n  res.status(204).send();\n});\n\napp.listen(3000);\n```\n\n> Tip: Usa códigos HTTP correctos: 200 OK, 201 Created, 204 No Content, 404 Not Found.',

  'Middleware y Autenticación': '## Middleware y Autenticación\n\nLos middleware son funciones que interceptan peticiones. JWT permite autenticación stateless ideal para APIs REST.\n\n```javascript\nconst jwt = require("jsonwebtoken");\nconst SECRET = "mi_secreto_seguro";\n\nfunction authMiddleware(req, res, next) {\n  const token = req.headers.authorization?.split(" ")[1];\n  if (!token) return res.status(401).json({ error: "Token requerido" });\n  try {\n    req.user = jwt.verify(token, SECRET);\n    next();\n  } catch {\n    res.status(403).json({ error: "Token inválido" });\n  }\n}\n\napp.get("/api/perfil", authMiddleware, (req, res) => {\n  res.json({ usuario: req.user });\n});\n```\n\n> Tip: Nunca almacenes secretos en el código. Usa variables de entorno con dotenv.',

  // --- Module 6: Bases de Datos ---

  'SQL con PostgreSQL': '## SQL con PostgreSQL\n\nPostgreSQL es una base de datos relacional robusta. SQL es el lenguaje estándar para consultar y manipular datos.\n\n```sql\nCREATE TABLE estudiantes (\n  id SERIAL PRIMARY KEY,\n  nombre VARCHAR(100) NOT NULL,\n  email VARCHAR(150) UNIQUE,\n  inscrito_en TIMESTAMP DEFAULT NOW()\n);\n\nINSERT INTO estudiantes (nombre, email)\nVALUES (\'Ana García\', \'ana@correo.com\');\n\nSELECT nombre, email\nFROM estudiantes\nWHERE inscrito_en > NOW() - INTERVAL \'30 days\'\nORDER BY nombre;\n```\n\n> Tip: Siempre usa consultas parametrizadas para prevenir inyección SQL.',

  'Firebase Realtime Database': '## Firebase Realtime Database\n\nFirebase RTDB es una base de datos NoSQL en la nube que sincroniza datos en tiempo real entre clientes.\n\n```javascript\nimport { getDatabase, ref, set, onValue } from "firebase/database";\n\nconst db = getDatabase();\n\n// Escribir datos\nawait set(ref(db, "usuarios/user1"), {\n  nombre: "Carlos",\n  curso: "Full Stack",\n  progreso: 45\n});\n\n// Leer en tiempo real\nonValue(ref(db, "usuarios/user1"), (snapshot) => {\n  const data = snapshot.val();\n  console.log("Datos:", data);\n});\n```\n\n> Tip: Estructura tus datos de forma plana en Firebase. Evita el anidamiento profundo para mejor rendimiento.',

  'ORM y Modelado de Datos': '## ORM y Modelado de Datos\n\nPrisma es un ORM moderno para TypeScript que genera tipos automáticamente y facilita las migraciones de base de datos.\n\n```typescript\n// schema.prisma\nmodel Estudiante {\n  id        Int      @id @default(autoincrement())\n  nombre    String\n  email     String   @unique\n  cursos    Curso[]\n}\n\n// Consulta con Prisma Client\nconst estudiantes = await prisma.estudiante.findMany({\n  where: { cursos: { some: { activo: true } } },\n  include: { cursos: true },\n  orderBy: { nombre: "asc" },\n});\n```\n\n> Tip: Usa prisma migrate dev para crear migraciones automáticas y prisma studio para explorar tus datos.',

  // --- Module 7: Despliegue y DevOps ---

  'Docker Basics': '## Docker Basics\n\nDocker permite empaquetar aplicaciones con todas sus dependencias en contenedores portables y reproducibles.\n\n```dockerfile\nFROM node:20-alpine\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production\nCOPY . .\nEXPOSE 3000\nCMD ["node", "dist/index.js"]\n```\n\n```yaml\n# docker-compose.yml\nservices:\n  app:\n    build: .\n    ports:\n      - "3000:3000"\n    environment:\n      - DATABASE_URL=postgres://db:5432/app\n  db:\n    image: postgres:16\n    volumes:\n      - pgdata:/var/lib/postgresql/data\nvolumes:\n  pgdata:\n```\n\n> Tip: Usa multi-stage builds para reducir el tamaño de la imagen final.',

  'CI/CD con GitHub Actions': '## CI/CD con GitHub Actions\n\nGitHub Actions automatiza pruebas y despliegue cada vez que se hace push o se crea un pull request.\n\n```yaml\nname: CI/CD Pipeline\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-node@v4\n        with:\n          node-version: 20\n      - run: npm ci\n      - run: npm test\n      - run: npm run build\n```\n\n> Tip: Agrega caching de node_modules para acelerar tus pipelines de CI/CD.',

  'Deploy en Vercel y Firebase': '## Deploy en Vercel y Firebase\n\nVercel es ideal para frontend React y Firebase Hosting para apps con backend serverless.\n\n```bash\n# Deploy frontend en Vercel\nnpm i -g vercel\nvercel --prod\n\n# Deploy en Firebase\nnpm i -g firebase-tools\nfirebase login\nfirebase init hosting\nnpm run build\nfirebase deploy --only hosting\n\n# Variables de entorno en Vercel\nvercel env add NEXT_PUBLIC_API_URL\n```\n\n> Tip: Configura preview deployments en Vercel para revisar cambios antes de ir a producción.',

  // ========== COURSE 1: Ciencia de Datos con Python ==========

  // --- Module 1: Python para Data Science ---

  'Jupyter Notebooks': '## Jupyter Notebooks\n\nJupyter es un entorno interactivo que permite combinar código, visualizaciones y texto en un mismo documento, ideal para análisis exploratorio.\n\n```python\n# Instalar e iniciar Jupyter\n# pip install jupyterlab\n# jupyter lab\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Cada celda se ejecuta independientemente\ndf = pd.read_csv("datos.csv")\ndf.head()\n\n# Las visualizaciones aparecen inline\ndf.plot(kind="bar", x="categoria", y="valor")\nplt.show()\n```\n\n> Tip: Usa atajos de teclado: Shift+Enter ejecuta celda, B crea celda abajo, M convierte a markdown.',

  'NumPy: Arrays y Operaciones': '## NumPy: Arrays y Operaciones\n\nNumPy es la librería fundamental para cómputo numérico en Python. Sus arrays son hasta 50x más rápidos que las listas nativas.\n\n```python\nimport numpy as np\n\n# Crear arrays\narr = np.array([1, 2, 3, 4, 5])\nmatriz = np.zeros((3, 4))\nrango = np.arange(0, 10, 0.5)\n\n# Operaciones vectorizadas (sin loops)\nresultado = arr * 2 + 1\nmedia = arr.mean()\nstd = arr.std()\n\n# Indexación avanzada\nmayores = arr[arr > 3]  # [4, 5]\n```\n\n> Tip: Evita loops de Python sobre arrays. Las operaciones vectorizadas de NumPy son mucho más eficientes.',

  'Estructuras de Datos en Python': '## Estructuras de Datos en Python\n\nPython ofrece estructuras de datos versátiles. Las comprensiones permiten transformar datos de forma concisa y legible.\n\n```python\n# Listas y comprensiones\nnumeros = [1, 2, 3, 4, 5]\ncuadrados = [n**2 for n in numeros if n > 2]\n\n# Diccionarios\nestudiante = {"nombre": "Ana", "edad": 22, "carrera": "DS"}\nnombres = {k: v for k, v in estudiante.items() if k != "edad"}\n\n# Sets para valores únicos\ntags = {"python", "data", "python"}  # {"python", "data"}\n\n# Tuplas inmutables\ncoordenada = (10.5, -3.2)\n```\n\n> Tip: Usa diccionarios para búsquedas O(1), sets para eliminar duplicados y tuplas para datos inmutables.',

  // --- Module 2: Pandas y Manipulación de Datos ---

  'DataFrames y Series': '## DataFrames y Series\n\nPandas es la librería esencial para manipulación de datos tabulares. Un DataFrame es como una tabla con filas y columnas etiquetadas.\n\n```python\nimport pandas as pd\n\n# Crear DataFrame\ndf = pd.DataFrame({\n    "nombre": ["Ana", "Luis", "María"],\n    "edad": [22, 25, 23],\n    "nota": [9.5, 8.0, 9.2]\n})\n\n# Explorar datos\nprint(df.shape)       # (3, 3)\nprint(df.describe())  # Estadísticas\nprint(df.dtypes)      # Tipos de columna\n\n# Filtrar\naprobados = df[df["nota"] >= 9.0]\n```\n\n> Tip: Siempre revisa df.info() y df.describe() al cargar un dataset nuevo para entender su estructura.',

  'Limpieza de Datos': '## Limpieza de Datos\n\nLa limpieza de datos es el paso más importante en cualquier proyecto. Datos sucios producen modelos incorrectos.\n\n```python\nimport pandas as pd\n\n# Valores nulos\ndf.isnull().sum()                    # Contar nulos por columna\ndf["edad"].fillna(df["edad"].median(), inplace=True)\ndf.dropna(subset=["email"])          # Eliminar filas sin email\n\n# Duplicados\ndf.drop_duplicates(subset=["email"], inplace=True)\n\n# Conversión de tipos\ndf["fecha"] = pd.to_datetime(df["fecha"])\ndf["precio"] = df["precio"].astype(float)\n```\n\n> Tip: Documenta cada paso de limpieza. La reproducibilidad es clave en ciencia de datos.',

  'Agrupación y Pivoteo': '## Agrupación y Pivoteo\n\nGroupBy permite agrupar datos y aplicar funciones de agregación. Pivot tables reorganizan datos para análisis cruzado.\n\n```python\nimport pandas as pd\n\n# GroupBy\nventas_por_region = df.groupby("region")["ventas"].agg([\n    "sum", "mean", "count"\n])\n\n# Pivot Table\ntabla = pd.pivot_table(df,\n    values="ventas",\n    index="region",\n    columns="trimestre",\n    aggfunc="sum"\n)\n\n# Merge (JOIN)\nresultado = pd.merge(clientes, pedidos, on="cliente_id", how="left")\n```\n\n> Tip: Usa agg() con diccionarios para aplicar diferentes funciones a diferentes columnas.',

  // --- Module 3: Visualización de Datos ---

  'Matplotlib Fundamentals': '## Matplotlib Fundamentals\n\nMatplotlib es la librería base de visualización en Python. Permite crear gráficos estáticos de alta calidad para publicaciones.\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Gráfico de líneas\nx = np.linspace(0, 10, 100)\naxes[0].plot(x, np.sin(x), label="sin(x)")\naxes[0].set_title("Función Seno")\naxes[0].legend()\n\n# Gráfico de barras\ncategorias = ["A", "B", "C"]\nvalores = [23, 45, 12]\naxes[1].bar(categorias, valores, color="steelblue")\naxes[1].set_title("Ventas")\n\nplt.tight_layout()\nplt.savefig("grafico.png", dpi=150)\n```\n\n> Tip: Usa plt.subplots() para crear figuras con múltiples gráficos y tight_layout() para evitar solapamiento.',

  'Seaborn para Estadísticas': '## Seaborn para Estadísticas\n\nSeaborn extiende Matplotlib con gráficos estadísticos elegantes y soporte nativo para DataFrames de Pandas.\n\n```python\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Distribución\nsns.histplot(data=df, x="edad", kde=True, bins=20)\n\n# Correlación\nsns.heatmap(df.corr(), annot=True, cmap="coolwarm", center=0)\n\n# Relación entre variables\nsns.scatterplot(data=df, x="horas_estudio", y="nota",\n                hue="aprobado", style="genero")\n\n# Comparación de categorías\nsns.boxplot(data=df, x="carrera", y="salario")\nplt.xticks(rotation=45)\nplt.show()\n```\n\n> Tip: Usa sns.set_theme() al inicio para aplicar estilos profesionales a todos tus gráficos.',

  'Dashboards con Plotly': '## Dashboards con Plotly\n\nPlotly crea visualizaciones interactivas para web. Con Dash puedes construir dashboards completos en Python.\n\n```python\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Gráfico interactivo rápido\nfig = px.scatter(df, x="ingreso", y="gasto",\n                 color="segmento", size="edad",\n                 hover_data=["nombre"],\n                 title="Ingreso vs Gasto")\nfig.show()\n\n# Gráfico personalizado\nfig = go.Figure()\nfig.add_trace(go.Bar(x=meses, y=ventas, name="Ventas"))\nfig.add_trace(go.Line(x=meses, y=meta, name="Meta"))\nfig.update_layout(template="plotly_dark")\n```\n\n> Tip: Plotly Express es ideal para exploración rápida. Usa Graph Objects cuando necesites personalización avanzada.',

  // --- Module 4: Estadística Aplicada ---

  'Estadística Descriptiva': '## Estadística Descriptiva\n\nLa estadística descriptiva resume las características principales de un dataset. Es el primer paso en cualquier análisis.\n\n```python\nimport numpy as np\nimport pandas as pd\n\ndata = pd.Series([23, 45, 12, 67, 34, 89, 23, 56])\n\nmedia = data.mean()         # Promedio\nmediana = data.median()     # Valor central\nstd = data.std()            # Desviación estándar\nq1 = data.quantile(0.25)    # Percentil 25\nq3 = data.quantile(0.75)    # Percentil 75\niqr = q3 - q1               # Rango intercuartílico\n\nprint(f"Media: {media:.2f}, Mediana: {mediana:.2f}")\nprint(f"IQR: {iqr:.2f}, Outliers < {q1 - 1.5*iqr:.2f}")\n```\n\n> Tip: Si la media difiere mucho de la mediana, tu distribución es sesgada. Usa la mediana como medida central.',

  'Probabilidad y Distribuciones': '## Probabilidad y Distribuciones\n\nLa distribución normal es fundamental en estadística. SciPy proporciona herramientas para trabajar con distribuciones de probabilidad.\n\n```python\nfrom scipy import stats\nimport numpy as np\n\n# Distribución Normal\nmu, sigma = 170, 10\ndist = stats.norm(loc=mu, scale=sigma)\n\nprob = dist.cdf(180)         # P(X <= 180)\nvalor = dist.ppf(0.95)       # Percentil 95\nmuestras = dist.rvs(size=1000)\n\n# Test de normalidad\nstat, p_value = stats.shapiro(muestras)\nprint(f"p-value: {p_value:.4f}")\nprint("Normal" if p_value > 0.05 else "No normal")\n```\n\n> Tip: El Teorema del Límite Central dice que la media de muestras grandes sigue una distribución normal.',

  'Tests de Hipótesis': '## Tests de Hipótesis\n\nLos tests de hipótesis permiten tomar decisiones basadas en datos. El p-value indica la probabilidad de obtener los resultados observados por azar.\n\n```python\nfrom scipy import stats\n\n# t-test: comparar dos grupos\ngrupo_a = [85, 90, 78, 92, 88]\ngrupo_b = [72, 68, 75, 80, 70]\nt_stat, p_value = stats.ttest_ind(grupo_a, grupo_b)\nprint(f"t={t_stat:.3f}, p={p_value:.4f}")\n\n# Chi-cuadrado: independencia\nobservado = [[30, 10], [20, 40]]\nchi2, p, dof, esperado = stats.chi2_contingency(observado)\nprint(f"Chi2={chi2:.3f}, p={p:.4f}")\nprint("Significativo" if p < 0.05 else "No significativo")\n```\n\n> Tip: Un p-value < 0.05 rechaza la hipótesis nula, pero siempre reporta el tamaño del efecto también.',

  // --- Module 5: Machine Learning Supervisado ---

  'Regresión Lineal y Logística': '## Regresión Lineal y Logística\n\nLa regresión lineal predice valores continuos y la logística clasifica en categorías. Scikit-learn unifica ambas con una API consistente.\n\n```python\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Regresión Lineal\nreg = LinearRegression()\nreg.fit(X_train, y_train)\nprint(f"R2 Score: {reg.score(X_test, y_test):.3f}")\n\n# Regresión Logística\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\nprint(f"Accuracy: {clf.score(X_test, y_test):.3f}")\n```\n\n> Tip: Siempre divide datos en train/test antes de entrenar. Nunca evalúes con los mismos datos de entrenamiento.',

  'Árboles de Decisión y Random Forest': '## Árboles de Decisión y Random Forest\n\nRandom Forest combina múltiples árboles de decisión para reducir overfitting y mejorar predicciones usando validación cruzada.\n\n```python\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nrf = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=10,\n    random_state=42\n)\n\n# Validación cruzada\nscores = cross_val_score(rf, X, y, cv=5, scoring="accuracy")\nprint(f"Accuracy: {scores.mean():.3f} +/- {scores.std():.3f}")\n\n# Importancia de features\nrf.fit(X_train, y_train)\nimportancia = pd.Series(rf.feature_importances_, index=X.columns)\nprint(importancia.sort_values(ascending=False).head(10))\n```\n\n> Tip: Revisa feature_importances_ para entender qué variables influyen más en las predicciones.',

  'Evaluación de Modelos': '## Evaluación de Modelos\n\nEvaluar modelos va más allá del accuracy. Precision, recall y AUC-ROC dan una visión completa del rendimiento.\n\n```python\nfrom sklearn.metrics import (\n    classification_report, roc_auc_score, confusion_matrix\n)\n\ny_pred = modelo.predict(X_test)\ny_prob = modelo.predict_proba(X_test)[:, 1]\n\n# Reporte completo\nprint(classification_report(y_test, y_pred))\n\n# AUC-ROC\nauc = roc_auc_score(y_test, y_prob)\nprint(f"AUC-ROC: {auc:.3f}")\n\n# Matriz de confusión\ncm = confusion_matrix(y_test, y_pred)\nprint(f"VP={cm[1,1]}, FP={cm[0,1]}, FN={cm[1,0]}, VN={cm[0,0]}")\n```\n\n> Tip: En datasets desbalanceados el accuracy engaña. Usa F1-score o AUC-ROC como métrica principal.',

  // --- Module 6: Machine Learning No Supervisado ---

  'Clustering con K-Means': '## Clustering con K-Means\n\nK-Means agrupa datos en K clusters basándose en similitud. El método del codo ayuda a elegir el número óptimo de clusters.\n\n```python\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Escalar datos\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Método del codo\ninercias = []\nfor k in range(1, 11):\n    km = KMeans(n_clusters=k, random_state=42)\n    km.fit(X_scaled)\n    inercias.append(km.inertia_)\n\nplt.plot(range(1, 11), inercias, marker="o")\nplt.xlabel("K"); plt.ylabel("Inercia")\nplt.title("Método del Codo")\nplt.show()\n```\n\n> Tip: Siempre escala tus datos antes de K-Means. El algoritmo es sensible a la magnitud de las variables.',

  'Reducción de Dimensionalidad (PCA)': '## Reducción de Dimensionalidad (PCA)\n\nPCA transforma datos de alta dimensión a un espacio de menor dimensión conservando la máxima varianza posible.\n\n```python\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# Escalar es obligatorio antes de PCA\nX_scaled = StandardScaler().fit_transform(X)\n\n# PCA con 2 componentes para visualización\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\nprint(f"Varianza explicada: {pca.explained_variance_ratio_}")\nprint(f"Total: {sum(pca.explained_variance_ratio_):.2%}")\n\n# Elegir componentes automáticamente\npca95 = PCA(n_components=0.95)  # Retiene 95% varianza\nX_reduced = pca95.fit_transform(X_scaled)\nprint(f"Dimensiones: {X.shape[1]} -> {X_reduced.shape[1]}")\n```\n\n> Tip: Usa PCA para visualizar datos multidimensionales en 2D o 3D antes de aplicar clustering.',

  'Detección de Anomalías': '## Detección de Anomalías\n\nIsolation Forest detecta anomalías aislando observaciones mediante particiones aleatorias. Las anomalías requieren menos particiones.\n\n```python\nfrom sklearn.ensemble import IsolationForest\nimport numpy as np\n\nmodel = IsolationForest(\n    n_estimators=100,\n    contamination=0.05,  # 5% de anomalías esperadas\n    random_state=42\n)\n\n# Entrenar y predecir\npredicciones = model.fit_predict(X)\n# 1 = normal, -1 = anomalía\n\nanomalias = X[predicciones == -1]\nnormales = X[predicciones == 1]\n\nprint(f"Anomalías detectadas: {len(anomalias)}")\nprint(f"Datos normales: {len(normales)}")\nscores = model.decision_function(X)\n```\n\n> Tip: Ajusta el parámetro contamination según el porcentaje de anomalías esperado en tu dominio.',

  // --- Module 7: Proyecto Final ---

  'Definición del Proyecto': '## Definición del Proyecto\n\nUn proyecto de ciencia de datos exitoso comienza con una planificación clara: objetivo de negocio, datos disponibles y métricas de éxito.\n\n```python\n# Estructura del Proyecto\n# proyecto/\n# ├── data/\n# │   ├── raw/           # Datos originales\n# │   └── processed/     # Datos limpios\n# ├── notebooks/\n# │   ├── 01_eda.ipynb\n# │   ├── 02_features.ipynb\n# │   └── 03_modeling.ipynb\n# ├── src/\n# │   ├── data_prep.py\n# │   └── model.py\n# ├── requirements.txt\n# └── README.md\n```\n\n> Tip: Define tu pregunta de negocio antes de tocar los datos. Un buen proyecto resuelve un problema real.',

  'EDA y Feature Engineering': '## EDA y Feature Engineering\n\nEl Análisis Exploratorio de Datos (EDA) revela patrones y guía la ingeniería de características para mejorar los modelos.\n\n```python\nimport pandas as pd\nimport seaborn as sns\n\n# EDA básico\ndf = pd.read_csv("datos.csv")\nprint(df.info())\nprint(df.describe())\nsns.pairplot(df, hue="target")\n\n# Feature Engineering\ndf["edad_grupo"] = pd.cut(df["edad"], bins=[0,25,40,60,100],\n                          labels=["joven","adulto","senior","mayor"])\ndf["ingreso_log"] = np.log1p(df["ingreso"])\ndf["ratio"] = df["gasto"] / df["ingreso"]\n\n# Encoding categórico\ndf_encoded = pd.get_dummies(df, columns=["region"], drop_first=True)\n```\n\n> Tip: Las features creadas manualmente con conocimiento del dominio suelen superar a las automáticas.',

  'Presentación de Resultados': '## Presentación de Resultados\n\nComunicar resultados de forma efectiva es tan importante como el análisis mismo. Adapta tu mensaje según la audiencia.\n\n### Estructura de Presentación\n\nComienza con el problema de negocio y el impacto esperado. Luego presenta los hallazgos principales con visualizaciones claras.\n\n### Métricas Clave\n\nSelecciona 3-5 métricas que tu audiencia pueda entender. Traduce métricas técnicas a impacto de negocio concreto.\n\n### Recomendaciones\n\nCierra con acciones específicas priorizadas por impacto y factibilidad. Incluye próximos pasos y limitaciones del análisis.\n\n> "Los mejores proyectos de data science no son los más complejos técnicamente, sino los que generan decisiones de negocio accionables."',

  // ========== COURSE 2: Inglés para Profesionales de TI ==========

  // --- Module 1: Technical Vocabulary ---

  'Programming Terms': '## Programming Terms\n\nMastering technical vocabulary in English is essential for reading documentation and communicating with international teams.\n\n```text\nAPI (Application Programming Interface) - Contract between software components\nSDK (Software Development Kit) - Tools to build for a platform\nCRUD - Create, Read, Update, Delete operations\nBoilerplate - Reusable template code\nRefactoring - Restructuring code without changing behavior\nTech Debt - Shortcuts that need future fixing\nDependency - External library your project relies on\nEndpoint - URL where an API receives requests\n```\n\n> Tip: Read English docs daily. Start with MDN Web Docs or React documentation to build vocabulary naturally.',

  'Infrastructure & Cloud': '## Infrastructure & Cloud\n\nCloud computing terms appear constantly in modern development. Understanding them is critical for DevOps conversations.\n\n```text\nCI/CD - Continuous Integration / Continuous Deployment\nContainer - Lightweight isolated environment (e.g., Docker)\nOrchestration - Managing multiple containers (e.g., Kubernetes)\nLoad Balancer - Distributes traffic across servers\nCDN - Content Delivery Network, caches content globally\nServerless - Run code without managing servers (e.g., AWS Lambda)\nVPC - Virtual Private Cloud, isolated network\nIaC - Infrastructure as Code (e.g., Terraform)\n```\n\n> Tip: Follow AWS or GCP blogs in English to stay current with cloud terminology and best practices.',

  'Agile & Project Management': '## Agile & Project Management\n\nScrum and Agile terms are used daily in international tech teams. Knowing them ensures smooth collaboration.\n\n```text\nSprint - Fixed time period for completing work (usually 2 weeks)\nBacklog - Prioritized list of pending work items\nStory Points - Relative effort estimation for tasks\nStandup - Brief daily meeting to share progress\nRetrospective - Team reflection meeting after a sprint\nEpic - Large feature broken into smaller stories\nVelocity - Amount of work completed per sprint\nDefinition of Done - Criteria for task completion\n```\n\n> Tip: Practice using these terms in sentences. Instead of "we need to talk about tasks," say "let\'s groom the backlog."',

  // --- Module 2: Reading Documentation ---

  'API Documentation': '## API Documentation\n\nReading API docs efficiently is a core developer skill. Focus on endpoints, methods, parameters, and response formats.\n\n```text\nEndpoint Structure:\n  METHOD /resource/:param\n  Headers: Authorization: Bearer <token>\n  Body: { "key": "value" }\n  Response: 200 OK { "data": [...] }\n\nExample:\n  GET  /api/users          -> List all users\n  GET  /api/users/:id      -> Get single user\n  POST /api/users          -> Create user\n  PUT  /api/users/:id      -> Update user\n  DELETE /api/users/:id    -> Delete user\n```\n\n> Tip: Always check the authentication section first, then look at rate limits before making your first API call.',

  'Stack Overflow & GitHub': '## Stack Overflow & GitHub\n\nAsking good questions and writing clear PR reviews in English accelerates your career and helps the community.\n\n```text\nAsking Questions (Stack Overflow):\n  1. Search existing answers first\n  2. Title: Specific error or goal\n  3. Body: What you tried, what happened, what you expected\n  4. Include minimal reproducible example\n  5. Don\'t say "it doesn\'t work" - describe the exact error\n\nPR Review Comments:\n  - "Could we consider using X instead?"\n  - "Nice approach! One suggestion..."\n  - "This might cause issues when..."\n  - "Nit: minor style suggestion"\n```\n\n> Tip: Use diplomatic language in code reviews. Say "What do you think about..." instead of "This is wrong."',

  'Technical Blogs & RFCs': '## Technical Blogs & RFCs\n\nTechnical articles and RFCs require different reading strategies. Learn to skim for relevance then deep-read what matters.\n\n```text\nSkimming Strategy (2-3 minutes):\n  1. Read title and subtitle\n  2. Scan headings and subheadings\n  3. Look at code examples and diagrams\n  4. Read conclusion first\n  5. Decide if full reading is worth it\n\nDeep Reading Strategy (15-30 minutes):\n  1. Read introduction fully\n  2. Take notes on key concepts\n  3. Run code examples locally\n  4. Summarize in your own words\n  5. Save useful snippets to your notes\n```\n\n> Tip: Subscribe to newsletters like TLDR, JavaScript Weekly, or Python Weekly for curated technical content.',

  // --- Module 3: Writing Skills ---

  'Professional Emails': '## Professional Emails\n\nClear professional emails save time and prevent misunderstandings. Follow a consistent structure for technical communication.\n\n```text\nSubject: [Action Required] API migration deadline - March 15\n\nHi [Name],\n\nI\'m writing regarding the API v2 migration for our project.\n\nContext: We need to migrate before the v1 deprecation date.\n\nAction items:\n  1. Review the migration guide (link attached)\n  2. Update endpoint URLs in staging by Friday\n  3. Run integration tests and share results\n\nPlease let me know if you have any questions or\nneed additional time.\n\nBest regards,\n[Your Name]\n```\n\n> Tip: Start with the purpose, provide context, list clear action items, and end with a call to action.',

  'Code Reviews & Comments': '## Code Reviews & Comments\n\nConstructive code reviews improve code quality and team learning. Use clear, respectful language that focuses on the code, not the person.\n\n```text\nPositive Feedback:\n  "Great use of the strategy pattern here!"\n  "This is well-structured and easy to follow."\n\nSuggestions:\n  "Have you considered using a Map instead of an object?"\n  "We could simplify this with optional chaining."\n\nConcerns:\n  "This might introduce a memory leak because..."\n  "I think we need error handling for the edge case when..."\n\nRequesting Changes:\n  "Could you add a unit test for the null input case?"\n  "Let\'s extract this into a utility function for reuse."\n```\n\n> Tip: Use "we" instead of "you" in reviews. "We should add tests" feels collaborative; "You forgot tests" feels accusatory.',

  'Technical Documentation': '## Technical Documentation\n\nGood documentation is the difference between a usable project and an abandoned one. Follow a clear template for consistency.\n\n```text\nREADME Template:\n\n# Project Name\nOne-line description of what it does.\n\n## Quick Start\n  $ npm install\n  $ npm run dev\n\n## Features\n  - Feature 1: Brief description\n  - Feature 2: Brief description\n\n## API Reference\n  GET /endpoint - Description\n  POST /endpoint - Description\n\n## Environment Variables\n  DATABASE_URL - Connection string\n  API_KEY - Third-party service key\n\n## Contributing\n  1. Fork the repo\n  2. Create a feature branch\n  3. Submit a pull request\n```\n\n> Tip: Write documentation as if the reader has never seen your project. The "curse of knowledge" is the biggest doc killer.',

  // --- Module 4: Speaking in Meetings ---

  'Daily Standups': '## Daily Standups\n\nDaily standups should be brief (under 2 minutes per person). Use a consistent structure to communicate status clearly.\n\n```text\nStandup Structure:\n\nYesterday:\n  "Yesterday I completed the user authentication flow\n   and merged the PR."\n\nToday:\n  "Today I\'m going to work on the payment integration\n   and write tests for the checkout module."\n\nBlockers:\n  "I\'m blocked on the database migration - I need\n   access credentials from the DevOps team."\n  "No blockers on my end."\n\nUseful Phrases:\n  "I\'m making good progress on..."\n  "I ran into an issue with..."\n  "I need help with..."\n```\n\n> Tip: Prepare your standup update before the meeting. Keep it focused on what the team needs to know.',

  'Technical Discussions': '## Technical Discussions\n\nIn technical discussions, diplomatic phrasing helps you disagree professionally and propose alternatives constructively.\n\n```text\nAgreeing:\n  "That makes sense. Building on that idea..."\n  "I agree with the approach. One addition..."\n\nDisagreeing Diplomatically:\n  "I see your point, but have we considered...?"\n  "That could work. Another option might be..."\n  "I have a slightly different perspective on this."\n\nProposing Solutions:\n  "What if we tried X approach instead?"\n  "Based on my experience with Y, I\'d suggest..."\n  "The trade-off here is between A and B."\n\nAsking for Clarification:\n  "Could you walk me through that again?"\n  "Just to make sure I understand correctly..."\n```\n\n> Tip: Never say "That won\'t work." Instead say "I think we might face challenges with X because..."',

  'Presenting Solutions': '## Presenting Solutions\n\nPresenting technical solutions clearly can make the difference between adoption and rejection. Structure your pitch logically.\n\n```text\nPresentation Framework (PREP):\n\n1. Problem:\n   "We\'re currently experiencing X, which causes Y."\n\n2. Recommendation:\n   "I propose we implement Z to solve this."\n\n3. Evidence:\n   "In our benchmarks, this approach showed\n    40% improvement in response time."\n   "Company ABC used this pattern successfully."\n\n4. Plan:\n   "Implementation would take 2 sprints.\n    Sprint 1: Core migration\n    Sprint 2: Testing and rollout"\n\nClosing:\n  "I\'d love to hear your thoughts on this approach."\n```\n\n> Tip: Always quantify the impact. "This will save 3 hours per week" is more convincing than "this will save time."',

  // --- Module 5: Interview Preparation ---

  'Behavioral Questions': '## Behavioral Questions\n\nBehavioral interviews assess soft skills through past experiences. The STAR method provides a clear framework for structured answers.\n\n```text\nSTAR Method:\n  S - Situation: Set the context\n  T - Task: Describe your responsibility\n  A - Action: Explain what you did\n  R - Result: Share the outcome (with metrics)\n\nExample:\n  Q: "Tell me about a time you solved a difficult bug."\n\n  S: "Our payment API was failing for 5% of users."\n  T: "I was assigned to investigate and fix it."\n  A: "I analyzed logs, reproduced the issue locally,\n      and found a race condition in the checkout flow.\n      I implemented a mutex lock and added retry logic."\n  R: "Error rate dropped to 0.1%, saving an estimated\n      $50K monthly in failed transactions."\n```\n\n> Tip: Prepare 5-7 STAR stories before interviews. Most behavioral questions can be answered with the same stories.',

  'Technical Interview Patterns': '## Technical Interview Patterns\n\nIn technical interviews, communication matters as much as the solution. Thinking aloud shows your problem-solving process.\n\n```text\nInterview Communication Framework:\n\n1. Clarify:\n   "Let me make sure I understand the requirements..."\n   "What are the input constraints?"\n   "Should I handle edge cases like empty input?"\n\n2. Plan:\n   "My approach would be to use a hash map because..."\n   "The time complexity would be O(n)."\n\n3. Code:\n   "I\'m starting with the main function..."\n   "Now I\'ll handle the edge case for..."\n\n4. Test:\n   "Let me trace through with this example..."\n   "Edge cases I want to verify: empty, single, large."\n\n5. Optimize:\n   "We could improve space complexity by..."\n```\n\n> Tip: It\'s okay to say "Let me think about this for a moment." Silence is better than rambling.',

  'System Design Discussions': '## System Design Discussions\n\nSystem design interviews test your ability to architect scalable solutions. Follow a structured approach and communicate trade-offs.\n\n```text\nSystem Design Framework:\n\n1. Requirements (3-5 min):\n   "What are the core features?"\n   "How many users should it support?"\n   "What are the latency requirements?"\n\n2. High-Level Design (10 min):\n   "I\'d start with these main components..."\n   Client -> Load Balancer -> API Servers -> DB\n\n3. Deep Dive (15 min):\n   "For the database, I\'d choose PostgreSQL because..."\n   "We\'d add Redis caching for frequently accessed data."\n\n4. Trade-offs (5 min):\n   "The trade-off between SQL and NoSQL here is..."\n   "We gain consistency but sacrifice write speed."\n```\n\n> Tip: Always discuss trade-offs. There is no perfect design, only designs that fit specific requirements.',

  // --- Module 6: Listening Comprehension ---

  'Tech Podcasts & Talks': '## Tech Podcasts & Talks\n\nRegular listening practice improves comprehension and exposes you to natural technical English and industry trends.\n\n```text\nRecommended Resources:\n  Podcasts:\n    - Syntax.fm (Web Development)\n    - Talk Python to Me (Python/Data Science)\n    - Software Engineering Daily (Architecture)\n    - The Changelog (Open Source)\n\n  Conference Talks:\n    - JSConf / PyCon recordings on YouTube\n    - Google I/O and WWDC sessions\n\nPractice Technique:\n  1. Listen once without subtitles\n  2. Listen again with English subtitles\n  3. Note new vocabulary and phrases\n  4. Summarize the talk in 3-5 sentences\n  5. Try explaining the topic to a colleague\n```\n\n> Tip: Start with podcasts at 0.75x speed, then gradually increase to 1.0x and eventually 1.25x.',

  'Accents & Speaking Styles': '## Accents & Speaking Styles\n\nTech teams are global. Understanding different English accents helps you collaborate effectively across cultures.\n\n```text\nCommon Accents in Tech:\n  American English:\n    - Dominant in tech (Silicon Valley influence)\n    - "Schedule" = SKED-ool\n    - Rhotic: R is always pronounced\n\n  British English:\n    - Common in European companies\n    - "Schedule" = SHED-yool\n    - Non-rhotic: R often silent\n\n  Indian English:\n    - Large presence in IT industry\n    - "Module" = MOD-yool\n    - Tends to be syllable-timed\n\n  Tips for Understanding:\n    - Focus on context, not individual words\n    - Watch tech talks from diverse speakers\n    - Ask for clarification politely when needed\n```\n\n> Tip: Expose yourself to diverse accents intentionally. YouTube tech channels from different countries are a great resource.',

  'Note-taking Strategies': '## Note-taking Strategies\n\nEffective note-taking during meetings ensures you capture decisions, action items, and technical details accurately.\n\n```text\nCornell Method for Meetings:\n\n+------------------+----------------------------+\n| Keywords/Cues    | Meeting Notes              |\n|                  |                            |\n| Decision:        | Team agreed to use Redis   |\n| migration        | for caching layer.         |\n|                  |                            |\n| Action: @Maria   | Update API endpoints by    |\n|                  | Friday March 15.           |\n|                  |                            |\n| Question:        | Need clarification on      |\n| auth flow        | OAuth vs JWT approach.     |\n|                  |                            |\n+------------------+----------------------------+\n| Summary: Migration to Redis approved.          |\n| Next steps: Maria updates API, team reviews.   |\n+------------------------------------------------+\n```\n\n> Tip: Write action items with a name and deadline. "Maria will update API by Friday" is better than "update API."',

  // --- Module 7: Real-world Practice ---

  'Open Source Contribution': '## Open Source Contribution\n\nContributing to open source builds your portfolio and English skills simultaneously. Start with documentation or small bug fixes.\n\n```text\nPull Request Template:\n\n## Description\nFix pagination bug in user list endpoint.\nThe offset calculation was incorrect when\npage size exceeded total results.\n\n## Changes\n- Fixed offset formula in UserService\n- Added boundary check for page parameter\n- Added unit tests for edge cases\n\n## Testing\n- [x] Unit tests pass\n- [x] Manual testing with edge cases\n- [x] No breaking changes to public API\n\n## Related Issues\nCloses #142\n```\n\n> Tip: Look for issues labeled "good first issue" or "help wanted." These are intentionally beginner-friendly tasks.',

  'Mock Interview': '## Mock Interview\n\nRegular mock interviews reduce anxiety and improve fluency. Practice with peers or recording yourself to identify weak areas.\n\n```text\nMock Interview Plan:\n\nPhase 1 - Warm Up (5 min):\n  "Tell me about yourself."\n  "Why are you interested in this role?"\n\nPhase 2 - Technical (25 min):\n  "Design a URL shortener service."\n  "Solve this coding problem: [problem]."\n  "How would you debug a slow API?"\n\nPhase 3 - Behavioral (15 min):\n  "Tell me about a challenging project."\n  "How do you handle disagreements?"\n  "Describe a time you failed and learned."\n\nPhase 4 - Questions (5 min):\n  "What does the team structure look like?"\n  "What are the biggest challenges ahead?"\n  "How do you measure success for this role?"\n```\n\n> Tip: Record your mock interviews. Reviewing them reveals filler words, pacing issues, and unclear explanations.',

  'Technical Presentation': '## Technical Presentation\n\nDelivering a clear technical presentation in English demonstrates expertise and communication skills valued by employers.\n\n```text\nPresentation Structure:\n\n1. Opening (1-2 min):\n   "Today I\'ll walk you through how we\n    improved our deployment pipeline."\n\n2. Problem Statement (2-3 min):\n   "Our deploys took 45 minutes and failed\n    30% of the time."\n\n3. Solution Deep Dive (10-15 min):\n   - Architecture diagram\n   - Key technical decisions\n   - Live demo (if possible)\n\n4. Results & Metrics (2-3 min):\n   "Deploy time reduced to 8 minutes.\n    Failure rate dropped to 2%."\n\n5. Lessons Learned (2 min):\n   "If I did it again, I would..."\n\n6. Q&A (5 min):\n   "I\'m happy to take any questions."\n```\n\n> Tip: Practice the opening 3 times. A strong start builds confidence for the rest of the presentation.',

};
